{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "causal_vae_dsprites.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajeyamk/causalvae/blob/dev-ajeya/causal_vae_dsprites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMhHGoIwCwkN",
        "colab_type": "code",
        "outputId": "64df98e6-9d63-4322-c5cf-3aef3c48e93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Install dependencies\n",
        "!pip3 install pyro-ppl\n",
        "!pip3 install torch torchvision\n",
        "!pip3 install pydrive --upgrade\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/0e/0523cb040c8f3ee8644b4280f6a72ed598ac7864680b667d6052fb5d445a/pyro-ppl-0.3.4.tar.gz (262kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.5.5)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.16.4)\n",
            "Collecting opt_einsum>=2.3.2 (from pyro-ppl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.1.0)\n",
            "Collecting tqdm>=4.31 (from pyro-ppl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyro-ppl, opt-einsum\n",
            "  Building wheel for pyro-ppl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyro-ppl: filename=pyro_ppl-0.3.4-cp36-none-any.whl size=365502 sha256=54f1e44799f5e07adbc1d58d64a001d9757c06029a11465daea27a1024170554\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/de/b5/88300d2adc973a7ec963b339d2935d34a0cf02c08b613a8a5e\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-2.3.2-cp36-none-any.whl size=49882 sha256=70b9c71b18c6d5a6d28ed53653d1d1680ce06ffc18d20b54bf10b4deb679df3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built pyro-ppl opt-einsum\n",
            "Installing collected packages: opt-einsum, tqdm, pyro-ppl\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed opt-einsum-2.3.2 pyro-ppl-0.3.4 tqdm-4.32.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K     |████████████████████████████████| 993kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.10)\n",
            "Requirement already satisfied, skipping upgrade: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydrive: filename=PyDrive-1.3.1-cp36-none-any.whl size=27435 sha256=c53725fe1f997c234eca6af9f8cb819deac873afe39086e3c810325019c6147d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.32.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNa3MO8GCqWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load necessary libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as dset\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import pyro\n",
        "from pyro.contrib.examples.util import print_and_log\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
        "from pyro.optim import Adam\n",
        "\n",
        "# Change figure aesthetics\n",
        "%matplotlib inline\n",
        "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n",
        "\n",
        "USE_CUDA = True\n",
        "\n",
        "pyro.enable_validation(True)\n",
        "pyro.distributions.enable_validation(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXRHmSqDFTy",
        "colab_type": "code",
        "outputId": "5f0f270f-32f2-4481-eb0e-338316981c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Mount Google drive to load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRCLhKI7d2r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount G drive to access files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqyc4SqyDLIq",
        "colab_type": "code",
        "outputId": "cc628455-ecfd-431b-c3db-1678e1628891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Hack to get all available GPU ram.\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=3f9a714ec53310c9a94be235a2c4af0fec033c74a2d12470c7f75aa640c55a7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 25.2 GB  | Proc size: 2.2 GB\n",
            "GPU RAM Free: 11107MB | Used: 334MB | Util   3% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSkXleG1CqWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, image_dim, label_dim, z_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.image_dim = image_dim\n",
        "        self.label_dim = label_dim\n",
        "        self.z_dim = z_dim\n",
        "        # setup the three linear transformations used\n",
        "        self.fc1 = nn.Linear(self.image_dim+self.label_dim, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 1000)\n",
        "        self.fc31 = nn.Linear(1000, z_dim)  # mu values\n",
        "        self.fc32 = nn.Linear(1000, z_dim)  # sigma values\n",
        "        # setup the non-linearities\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, xs, ys):\n",
        "        # define the forward computation on the image xs and label ys\n",
        "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
        "        xs = xs.reshape(-1, self.image_dim)\n",
        "        #now concatenate the image and label\n",
        "        inputs = torch.cat((xs,ys), -1)\n",
        "        # then compute the hidden units\n",
        "        hidden1 = self.softplus(self.fc1(inputs))\n",
        "        hidden2 = self.softplus(self.fc2(hidden1))\n",
        "        # then return a mean vector and a (positive) square root covariance\n",
        "        # each of size batch_size x z_dim\n",
        "        z_loc = self.fc31(hidden2)\n",
        "        z_scale = torch.exp(self.fc32(hidden2))\n",
        "        return z_loc, z_scale\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, image_dim, label_dim, z_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        # setup the two linear transformations used\n",
        "        hidden_dim = 1000\n",
        "        self.fc1 = nn.Linear(z_dim+label_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, image_dim)\n",
        "        # setup the non-linearities\n",
        "        self.softplus = nn.Softplus()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, zs, ys):\n",
        "        # define the forward computation on the latent z and label y\n",
        "        # first concatenate z and y\n",
        "        inputs = torch.cat((zs, ys),-1)\n",
        "        # then compute the hidden units\n",
        "        hidden1 = self.softplus(self.fc1(inputs))\n",
        "        hidden2 = self.softplus(self.fc2(hidden1))\n",
        "        hidden3 = self.softplus(self.fc3(hidden2))\n",
        "        # return the parameter for the output Bernoulli\n",
        "        # each is of size batch_size x 784\n",
        "        loc_img = self.sigmoid(self.fc4(hidden3))\n",
        "        return loc_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqj05Mv8CqWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CVAE(nn.Module):\n",
        "\n",
        "    def __init__(self, config_enum=None, use_cuda=False, aux_loss_multiplier=None):\n",
        "\n",
        "        super(CVAE, self).__init__()\n",
        "    \n",
        "        self.image_dim = 64**2\n",
        "        self.label_shape = np.array((1,3,6,40,32,32))\n",
        "        self.label_names = np.array(('color', 'shape', 'scale', 'orientation', 'posX', 'posY'))\n",
        "        self.label_dim = np.sum(self.label_shape)\n",
        "        self.z_dim = 50                                           \n",
        "        self.allow_broadcast = config_enum == 'parallel'\n",
        "        self.use_cuda = use_cuda\n",
        "        self.aux_loss_multiplier = aux_loss_multiplier\n",
        "\n",
        "        # define and instantiate the neural networks representing\n",
        "        # the paramters of various distributions in the model\n",
        "        self.setup_networks()\n",
        "\n",
        "    def setup_networks(self):\n",
        "        self.encoder = Encoder(self.image_dim, self.label_dim, self.z_dim)\n",
        "\n",
        "        self.decoder = Decoder(self.image_dim, self.label_dim, self.z_dim)\n",
        "\n",
        "        # using GPUs for faster training of the networks\n",
        "        if self.use_cuda:\n",
        "            self.cuda()\n",
        "\n",
        "    def model(self, xs, ys):\n",
        "        \"\"\"\n",
        "        The model corresponds to the following generative process:\n",
        "        p(z) = normal(0,I)              # dsprites label (latent)\n",
        "        p(y|x) = categorical(I/10.)     # which digit (supervised)\n",
        "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
        "        loc is given by a neural network  `decoder`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :param ys: a batch of the class labels i.e.\n",
        "                   the digit corresponding to the image(s)\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # register this pytorch module and all of its sub-modules with pyro\n",
        "        pyro.module(\"cvae\", self)\n",
        "\n",
        "        batch_size = xs.size(0)\n",
        "        options = dict(dtype=xs.dtype, device=xs.device)\n",
        "        with pyro.plate(\"data\"):\n",
        "\n",
        "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
        "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
        "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
        "            \n",
        "            # if the label y (which digit to write) is supervised, sample from the\n",
        "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
        "    \n",
        "            loc = self.decoder.forward(zs, self.remap_y(ys))\n",
        "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
        "            # return the loc so we can visualize it later\n",
        "            return loc\n",
        "\n",
        "    def guide(self, xs, ys):\n",
        "        \"\"\"\n",
        "        The guide corresponds to the following:\n",
        "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer latent class from an image and the label \n",
        "        loc, scale are given by a neural network `encoder`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # inform Pyro that the variables in the batch of xs are conditionally independent\n",
        "        with pyro.plate(\"data\"):\n",
        "            # sample (and score) the latent handwriting-style with the variational\n",
        "            # distribution q(z|x) = normal(loc(x),scale(x))\n",
        "    \n",
        "            loc, scale = self.encoder.forward(xs, self.remap_y(ys))\n",
        "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
        "            \n",
        "    def remap_y(self, ys):\n",
        "        new_ys = []\n",
        "        options = dict(dtype=ys.dtype, device=ys.device)\n",
        "        for i, label_length in enumerate(self.label_shape):\n",
        "            prior = torch.ones(ys.size(0), label_length, **options) / (1.0 * label_length)\n",
        "            new_ys.append(pyro.sample(\"y_%s\" % self.label_names[i], dist.OneHotCategorical(prior), \n",
        "                                   obs=torch.nn.functional.one_hot(ys[:,i].to(torch.int64), int(label_length))))\n",
        "        new_ys = torch.cat(new_ys, -1)\n",
        "        return new_ys.to(torch.float32)\n",
        "            \n",
        "    def reconstruct_image(self, xs, ys):\n",
        "        # backward\n",
        "        sim_z_loc, sim_z_scale = self.encoder.forward(xs, self.remap_y(ys))\n",
        "        zs = dist.Normal(sim_z_loc, sim_z_scale).to_event(1).sample()\n",
        "        # forward\n",
        "        loc = self.decoder.forward(zs, self.remap_y(ys))\n",
        "        return dist.Bernoulli(loc).to_event(1).sample()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmMe3D8CqWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_data_loaders(train_x, test_x, train_y, test_y, batch_size=128, use_cuda=False):\n",
        "    train_dset = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(train_x.astype(np.float32)).reshape(-1, 4096),\n",
        "        torch.from_numpy(train_y.astype(np.float32))\n",
        "    )\n",
        "    \n",
        "    test_dset = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(test_x.astype(np.float32)).reshape(-1, 4096),\n",
        "        torch.from_numpy(test_y.astype(np.float32))\n",
        "    )    \n",
        "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
        "    )\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=test_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
        "    )\n",
        "    \n",
        "    return {\"train\":train_loader, \"test\":test_loader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azMSBtsnCqWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_zip = np.load(\n",
        "    '/content/gdrive/My Drive/data-science/causal-ml/projects/dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
        "    encoding = 'bytes',\n",
        "    allow_pickle=True\n",
        ")\n",
        "imgs = dataset_zip['imgs']\n",
        "labels = dataset_zip['latents_classes']\n",
        "label_sizes = dataset_zip['metadata'][()][b'latents_sizes']\n",
        "label_names = dataset_zip['metadata'][()][b'latents_names']\n",
        "\n",
        "# Sample imgs randomly\n",
        "indices_sampled = np.arange(imgs.shape[0])\n",
        "np.random.shuffle(indices_sampled)\n",
        "imgs_sampled = imgs[indices_sampled]\n",
        "labels_sampled = labels[indices_sampled]\n",
        "\n",
        "data_loaders = setup_data_loaders(\n",
        "    imgs_sampled[1000:],\n",
        "    imgs_sampled[:1000],\n",
        "    labels_sampled[1000:],\n",
        "    labels_sampled[:1000],\n",
        "    batch_size=256,\n",
        "    use_cuda=USE_CUDA\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eamf-n9hCqWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(svi, train_loader, use_cuda=False):\n",
        "    # initialize loss accumulator\n",
        "    epoch_loss = 0.\n",
        "    # do a training epoch over each mini-batch x returned\n",
        "    # by the data loader\n",
        "    for xs,ys in train_loader:\n",
        "        # if on GPU put mini-batch into CUDA memory\n",
        "        if use_cuda:\n",
        "            xs = xs.cuda()\n",
        "            ys = ys.cuda()\n",
        "        # do ELBO gradient and accumulate loss\n",
        "        epoch_loss += svi.step(xs, ys)\n",
        "\n",
        "    # return epoch loss\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
        "    return total_epoch_loss_train\n",
        "\n",
        "def evaluate(svi, test_loader, use_cuda=False):\n",
        "    # initialize loss accumulator\n",
        "    test_loss = 0.\n",
        "    # compute the loss over the entire test set\n",
        "    for xs, ys in test_loader:\n",
        "        # if on GPU put mini-batch into CUDA memory\n",
        "        if use_cuda:\n",
        "            xs = xs.cuda()\n",
        "            ys = ys.cuda()\n",
        "        # compute ELBO estimate and accumulate loss\n",
        "        test_loss += svi.evaluate_loss(xs, ys)\n",
        "    normalizer_test = len(test_loader.dataset)\n",
        "    total_epoch_loss_test = test_loss / normalizer_test\n",
        "    return total_epoch_loss_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR-hW5UzCqWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run options\n",
        "LEARNING_RATE = 1.0e-3\n",
        "\n",
        "# Run only for a single iteration for testing\n",
        "NUM_EPOCHS = 10\n",
        "TEST_FREQUENCY = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puMbph4idkYg",
        "colab_type": "code",
        "outputId": "c693775f-ff79-4f6f-9fcc-a0799ea0123a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#################################\n",
        "### FOR SAVING AND LOADING MODEL\n",
        "################################\n",
        "# clear param store\n",
        "\n",
        "pyro.clear_param_store()\n",
        "\n",
        "network_path = \"/content/gdrive/My Drive/data-science/causal-ml/projects/trained_model.save\"\n",
        "\n",
        "PATH = \"trained_model.save\"\n",
        "\n",
        "# new model\n",
        "# vae = CVAE(use_cuda=USE_CUDA)\n",
        "\n",
        "# save current model\n",
        "# torch.save(vae.state_dict(), PATH)\n",
        "\n",
        "# to load params from trained model\n",
        "vae = CVAE(use_cuda=USE_CUDA)\n",
        "vae.load_state_dict(torch.load(network_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtCW3_agE7N_",
        "colab_type": "text"
      },
      "source": [
        "### **DONT RUN THE BELOW CODE AS WE'VE ALREADY TRAINED THE MODEL AND WE'VE STORED THE NETWORK PARAMS**\n",
        "\n",
        "## =================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIuVKC2lCqWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# clear param store\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# setup the VAE\n",
        "vae = CVAE(use_cuda=USE_CUDA)\n",
        "\n",
        "# setup the optimizer\n",
        "adam_args = {\"lr\": LEARNING_RATE}\n",
        "optimizer = Adam(adam_args)\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "train_elbo = []\n",
        "test_elbo = []\n",
        "# training loop\n",
        "\n",
        "VERBOSE = True\n",
        "pbar = tqdm(range(NUM_EPOCHS))\n",
        "for epoch in pbar:\n",
        "    total_epoch_loss_train = train(svi, data_loaders[\"train\"], use_cuda=USE_CUDA)\n",
        "    train_elbo.append(-total_epoch_loss_train)\n",
        "    if VERBOSE:\n",
        "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
        "\n",
        "    if epoch % TEST_FREQUENCY == 0:\n",
        "        # report test diagnostics\n",
        "        total_epoch_loss_test = evaluate(svi, data_loaders[\"test\"], use_cuda=USE_CUDA)\n",
        "        test_elbo.append(-total_epoch_loss_test)\n",
        "        if VERBOSE:\n",
        "            print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "navbYZazFD0E",
        "colab_type": "text"
      },
      "source": [
        "## =================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFnfYMd3CqW0",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing the reconstruction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIt0T2eUCqW0",
        "colab_type": "code",
        "outputId": "3e998cf8-ca4b-44ca-fc77-909d5d5427c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_iter = iter(data_loaders[\"train\"])\n",
        "xs, ys = next(data_iter)\n",
        "if USE_CUDA:\n",
        "    xs = xs.cuda()\n",
        "    ys = ys.cuda()\n",
        "rs = vae.reconstruct_image(xs, ys)\n",
        "if USE_CUDA:\n",
        "    xs = xs.cpu()\n",
        "    rs = rs.cpu()\n",
        "originals = xs.numpy().reshape(-1, 64,64)\n",
        "recons = rs.numpy().reshape(-1,64,64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_color\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_shape\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_scale\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_orientation\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_posX\n",
            "  RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:85: RuntimeWarning: trying to observe a value outside of inference at y_posY\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YBT2lo7CqW2",
        "colab_type": "code",
        "outputId": "41409e8c-1377-40fb-ae00-85c1033e4c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def f(x):\n",
        "    fig = plt.figure()\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    plt.imshow(originals[x], cmap='Greys_r',  interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    ax1 = fig.add_subplot(122)\n",
        "    plt.imshow(recons[x], cmap='Greys_r',  interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "interact(f, x=widgets.IntSlider(min=0, max=xs.shape[0], step=1, value=0));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa5408ccd61549d39b5bb6f31f00d45e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='x', max=256), Output()), _dom_classes=('widget-interact'…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLOw_NXQziDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SCM(vae, mu, sigma):\n",
        "    z_dim = vae.z_dim\n",
        "    Ny, Y, ys = [], [], []\n",
        "    \n",
        "    Nx = pyro.sample(\"Nx\", dist.Uniform(torch.zeros(vae.image_dim), torch.ones(vae.image_dim)))\n",
        "    Nz = pyro.sample(\"Nz\", dist.Normal(torch.zeros(z_dim), torch.ones(z_dim)))\n",
        "    m = torch.distributions.gumbel.Gumbel(torch.tensor(0.0), torch.tensor(1.0))\n",
        "    for label_id in range(6):\n",
        "        name = vae.label_names[label_id]\n",
        "        length = vae.label_shape[label_id]\n",
        "        new = pyro.sample(\"Ny_%s\"%name, dist.Uniform(torch.zeros(length), torch.ones(length)) )\n",
        "        Ny.append(new)\n",
        "        gumbel_vars = torch.tensor([m.sample() for _ in range(length)])\n",
        "        max_ind = torch.argmax(torch.log(new) + gumbel_vars).item()\n",
        "        Y.append(pyro.sample(\"Y_%s\"%name, dist.Delta(torch.tensor(max_ind))))\n",
        "        ys.append(torch.nn.functional.one_hot(torch.tensor(max_ind), int(length)))        \n",
        "    Y = torch.tensor(Y)\n",
        "    ys = torch.cat(ys).to(torch.float32).reshape(1,-1).cuda()\n",
        "    Z = pyro.sample(\"Z\", dist.Delta(mu + Nz*sigma))\n",
        "    zs = Z.cuda()\n",
        "    p = vae.decoder.forward(zs,ys).cpu()\n",
        "    X = pyro.sample(\"X\", dist.Delta(Nx < p))\n",
        "    return X, Y, Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNzpNC4EzkA6",
        "colab_type": "code",
        "outputId": "25094bd0-cc7b-47b3-ce5f-f05c6cb46e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "xs, ys = next(data_iter)\n",
        "x = xs[0].reshape(1,-1).cuda()\n",
        "y = ys[0].reshape(1,-1).cuda()\n",
        "mu, sigma = vae.encoder.forward(x,vae.remap_y(y))\n",
        "mu = mu.cpu()\n",
        "sigma = sigma.cpu()\n",
        "recon_x1,y1,z1 = SCM(vae, mu, sigma)\n",
        "y1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  5, 19, 29, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0EX3FetiTi-",
        "colab_type": "code",
        "outputId": "bab4738c-ea3c-43c9-d50e-f272cca391c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from pyro.infer.importance import Importance\n",
        "from pyro.infer.mcmc import MCMC\n",
        "from pyro.infer.mcmc.nuts import HMC\n",
        "\n",
        "\n",
        "# intervened_model = pyro.do(SCM, data={\"Y_shape\": torch.tensor(1)})\n",
        "conditioned_model = pyro.condition(SCM, data={\n",
        "                                       \"X\": recon_x1, \n",
        "                                       \"Y_shape\": torch.tensor(0),\n",
        "                                       \"Z\":z1})\n",
        "\n",
        "kernel = HMC(conditioned_model, step_size=0.8, num_steps=4)\n",
        "posterior = MCMC(kernel, num_samples=1000, warmup_steps=50)\n",
        "\n",
        "# posterior = pyro.infer.Importance(conditioned_model, num_samples = 1)\n",
        "posterior.run(vae, mu, sigma)\n",
        "\n",
        "print(type(posterior))\n",
        "print(posterior)\n",
        "\n",
        "result = []\n",
        "for i in range(10):\n",
        "  trace = posterior()\n",
        "  x = trace.nodes['Nx']['value']\n",
        "  y = trace.nodes['Ny']['value']\n",
        "  z = trace.nodes['Nz']['value']\n",
        "  con_obj = pyro.condition(intervened_model, data = {\"Nx\": x,\"Ny\": y, \"Nz\": z})\n",
        "#   result.append(con_obj()[2])\n",
        "  \n",
        "# recon_x2,y2,z2 = con_obj(vae, mu, sigma)\n",
        "# print(y2)\n",
        "# recon_check(recon_x1.reshape(-1, 64, 64)[0], recon_x2.reshape(-1, 64, 64)[0])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rWarmup:   0%|          | 0/1050 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-e9b8f1bbb3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# posterior = pyro.infer.Importance(conditioned_model, num_samples = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/abstract_infer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0mchain_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/mcmc.py\u001b[0m in \u001b[0;36m_traces\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/mcmc.py\u001b[0m in \u001b[0;36m_traces\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_multiprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/hmc.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, warmup_steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_model_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mpotential_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/hmc.py\u001b[0m in \u001b[0;36m_initialize_model_properties\u001b[0;34m(self, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mjit_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mskip_jit_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_jit_warnings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotential_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/util.py\u001b[0m in \u001b[0;36minitialize_model\u001b[0;34m(model, model_args, model_kwargs, transforms, max_plate_nesting, jit_compile, jit_options, skip_jit_warnings, num_chains)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# enable potential_fn to be picklable (a torch._C.Function cannot be pickled).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     init_params = _get_init_params(model, model_args, model_kwargs, transforms,\n\u001b[0;32m--> 394\u001b[0;31m                                    pe_maker.get_potential_fn(), prototype_params, num_chains=num_chains)\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0mpotential_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_potential_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_jit_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/util.py\u001b[0m in \u001b[0;36m_get_init_params\u001b[0;34m(model, model_args, model_kwargs, transforms, potential_fn, prototype_params, max_tries_initial_params, num_chains, strategy)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 params = {k: dist.Uniform(v.new_full(v.shape, -2), v.new_full(v.shape, 2)).sample()\n\u001b[0;32m--> 303\u001b[0;31m                           for k, v in params.items()}\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prior\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/mcmc/util.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 params = {k: dist.Uniform(v.new_full(v.shape, -2), v.new_full(v.shape, 2)).sample()\n\u001b[0;32m--> 303\u001b[0;31m                           for k, v in params.items()}\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prior\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/uniform.py\u001b[0m in \u001b[0;36mrsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: _th_uniform_ not supported on CPUType for Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZQ_mi_GMm_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [ 0,  2,  1, 34,  4, 24]\n",
        "def recon_check(original, recon):\n",
        "  fig = plt.figure()\n",
        "  ax0 = fig.add_subplot(121)\n",
        "  plt.imshow(original, cmap='Greys_r',  interpolation='nearest')\n",
        "  plt.axis('off')\n",
        "  ax1 = fig.add_subplot(122)\n",
        "  plt.imshow(recon , cmap='Greys_r', interpolation='nearest')\n",
        "  plt.axis('off')\n",
        "    \n",
        "\n",
        "def show_density(img1, img2):\n",
        "  fig = plt.figure()\n",
        "  ax0 = fig.add_subplot(121)\n",
        "  plt.imshow(img1.mean(axis=0), cmap='Greys_r',  interpolation='nearest')\n",
        "  plt.axis('off')\n",
        "  ax1 = fig.add_subplot(122)\n",
        "  plt.imshow(img2.mean(axis=0) , cmap='Greys_r', interpolation='nearest')\n",
        "  plt.axis('off')\n",
        "  \n",
        "  \n",
        "def show_density2(imgs):\n",
        "  _, ax = plt.subplots()\n",
        "  ax.imshow(imgs.mean(), interpolation='nearest', cmap='Greys_r')\n",
        "  ax.grid('off')\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  \n",
        "\n",
        "latents_bases = np.concatenate((label_sizes[::-1].cumprod()[::-1][1:],\n",
        "                                np.array([1,])))\n",
        "\n",
        "def latent_to_index(latents):\n",
        "  return np.dot(latents, latents_bases).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}