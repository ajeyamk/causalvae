{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae-ajeya.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajeyamk/causalvae/blob/master/vae_ajeya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rtbzfmeMGvr",
        "colab_type": "code",
        "outputId": "d660dcf8-0f0d-48dc-bad5-3ece0577785c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        }
      },
      "source": [
        "!pip3 install pyro-ppl\n",
        "!pip3 install torch torchvision\n",
        "!pip3 install pydrive --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/0e/0523cb040c8f3ee8644b4280f6a72ed598ac7864680b667d6052fb5d445a/pyro-ppl-0.3.4.tar.gz (262kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.5.5)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.16.4)\n",
            "Collecting opt_einsum>=2.3.2 (from pyro-ppl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.1.0)\n",
            "Collecting tqdm>=4.31 (from pyro-ppl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 24.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyro-ppl, opt-einsum\n",
            "  Building wheel for pyro-ppl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/de/b5/88300d2adc973a7ec963b339d2935d34a0cf02c08b613a8a5e\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built pyro-ppl opt-einsum\n",
            "Installing collected packages: opt-einsum, tqdm, pyro-ppl\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed opt-einsum-2.3.2 pyro-ppl-0.3.4 tqdm-4.32.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.9)\n",
            "Requirement already satisfied, skipping upgrade: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OouaeUpQMEjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as dset\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pyro\n",
        "from pyro.contrib.examples.util import print_and_log\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
        "from pyro.optim import Adam\n",
        "\n",
        "# Change figure aesthetics\n",
        "%matplotlib inline\n",
        "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n",
        "\n",
        "USE_CUDA = True\n",
        "\n",
        "pyro.enable_validation(True)\n",
        "pyro.distributions.enable_validation(False)\n",
        "\n",
        "# from custom_mlp import MLP, Exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1p7kozIT9YN",
        "colab_type": "code",
        "outputId": "c862df8b-a7f9-4c4f-af2c-a2dcdea2c83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux30_pwSUEJX",
        "colab_type": "code",
        "outputId": "3737184a-2209-46cf-9495-2019b4b3363a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Hack to get all available GPU ram.\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.7 GB  | Proc size: 3.5 GB\n",
            "GPU RAM Free: 14310MB | Used: 769MB | Util   5% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXd84WMYr3W",
        "colab_type": "code",
        "outputId": "9bcc6312-9aef-4655-ca3f-7606949251bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GhM07OkM4_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8E4_2q1NTZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/open?id=1mAtimHIWHJM2UJNxsIylPyI1jUebGIx-\n",
        "custom_mlp_module = drive.CreateFile({'id':'1mAtimHIWHJM2UJNxsIylPyI1jUebGIx-'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-A-TTIFPfip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_mlp = custom_mlp_module.GetContentFile('custom_mlp.py')\n",
        "from custom_mlp import MLP, Exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vomid1y5MEjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    This class encapsulates the parameters (neural networks) and models & guides needed to train a\n",
        "    semi-supervised variational auto-encoder on the Dsprites image dataset\n",
        "\n",
        "    :param output_size: size of the tensor representing the class label \n",
        "    :param input_size: size of the tensor representing the image (64*64 = 4096 for our Dsprites dataset\n",
        "                       since we flatten the images and scale the pixels to be in [0,1])\n",
        "    :param z_dim: size of the tensor representing the latent random variable z\n",
        "                  (for our Dsprites dataset)\n",
        "    :param hidden_layers: a tuple (or list) of MLP layers to be used in the neural networks\n",
        "                          representing the parameters of the distributions in our model\n",
        "    :param use_cuda: use GPUs for faster training\n",
        "    :param aux_loss_multiplier: the multiplier to use with the auxiliary loss\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size=6, input_size=4096, z_dim=50, hidden_layers=(500,),\n",
        "                 config_enum=None, use_cuda=USE_CUDA, aux_loss_multiplier=None):\n",
        "\n",
        "        super(SVAE, self).__init__()\n",
        "\n",
        "        # initialize the class with all arguments provided to the constructor\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.z_dim = z_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.allow_broadcast = config_enum == 'parallel'\n",
        "        self.use_cuda = use_cuda\n",
        "        self.aux_loss_multiplier = aux_loss_multiplier\n",
        "\n",
        "        # define and instantiate the neural networks representing\n",
        "        # the paramters of various distributions in the model\n",
        "        self.setup_networks()\n",
        "\n",
        "    def setup_networks(self):\n",
        "\n",
        "        z_dim = self.z_dim\n",
        "        hidden_sizes = self.hidden_layers\n",
        "\n",
        "        # define the neural networks used later in the model and the guide.\n",
        "        # these networks are MLPs (multi-layered perceptrons or simple feed-forward networks)\n",
        "        # where the provided activation parameter is used on every linear layer except\n",
        "        # for the output layer where we use the provided output_activation parameter\n",
        "        self.encoder_y = MLP([self.input_size] + hidden_sizes + [self.output_size],\n",
        "                             activation=nn.Softplus,\n",
        "                             output_activation=nn.Softmax,\n",
        "                             allow_broadcast=self.allow_broadcast,\n",
        "                             use_cuda=self.use_cuda)\n",
        "\n",
        "        # a split in the final layer's size is used for multiple outputs\n",
        "        # and potentially applying separate activation functions on them\n",
        "        # e.g. in this network the final output is of size [z_dim,z_dim]\n",
        "        # to produce loc and scale, and apply different activations [None,Exp] on them\n",
        "        self.encoder_z = MLP([self.input_size + self.output_size] +\n",
        "                             hidden_sizes + [[z_dim, z_dim]],\n",
        "                             activation=nn.Softplus,\n",
        "                             output_activation=[None, Exp],\n",
        "                             allow_broadcast=self.allow_broadcast,\n",
        "                             use_cuda=self.use_cuda)\n",
        "\n",
        "        self.decoder = MLP([z_dim + self.output_size] +\n",
        "                           hidden_sizes + [self.input_size],\n",
        "                           activation=nn.Softplus,\n",
        "                           output_activation=nn.Sigmoid,\n",
        "                           allow_broadcast=self.allow_broadcast,\n",
        "                           use_cuda=self.use_cuda)\n",
        "\n",
        "        # using GPUs for faster training of the networks\n",
        "        if self.use_cuda:\n",
        "            self.cuda()\n",
        "\n",
        "    def model(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        The model corresponds to the following generative process:\n",
        "        p(z) = normal(0,I)              # dsprites label (latent)\n",
        "        p(y|x) = categorical(I/10.)     # which digit (supervised)\n",
        "        p(x|y,z) = bernoulli(loc(y,z))   # an image\n",
        "        loc is given by a neural network  `decoder`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :param ys: (optional) a batch of the class labels i.e.\n",
        "                   the digit corresponding to the image(s)\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # register this pytorch module and all of its sub-modules with pyro\n",
        "        pyro.module(\"ss_vae\", self)\n",
        "\n",
        "        batch_size = xs.size(0)\n",
        "        options = dict(dtype=xs.dtype, device=xs.device)\n",
        "        with pyro.plate(\"data\"):\n",
        "\n",
        "            # sample the handwriting style from the constant prior distribution\n",
        "            prior_loc = torch.zeros(batch_size, self.z_dim, **options)\n",
        "            prior_scale = torch.ones(batch_size, self.z_dim, **options)\n",
        "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
        "\n",
        "            # if the label y (which digit to write) is supervised, sample from the\n",
        "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
        "            alpha_prior = torch.ones(batch_size, self.output_size, **options) / (1.0 * self.output_size)\n",
        "            ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha_prior), obs=ys)\n",
        "\n",
        "            # finally, score the image (x) using the handwriting style (z) and\n",
        "            # the class label y (which digit to write) against the\n",
        "            # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
        "            # where `decoder` is a neural network\n",
        "            loc = self.decoder.forward([zs, ys])\n",
        "            pyro.sample(\"x\", dist.Bernoulli(loc).to_event(1), obs=xs)\n",
        "            # return the loc so we can visualize it later\n",
        "            return loc\n",
        "\n",
        "    def guide(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        The guide corresponds to the following:\n",
        "        q(y|x) = categorical(alpha(x))              # infer label from an image\n",
        "        q(z|x,y) = normal(loc(x,y),scale(x,y))       # infer latent class from an image and the label\n",
        "        loc, scale are given by a neural network `encoder_z`\n",
        "        alpha is given by a neural network `encoder_y`\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :param ys: (optional) a batch of the class labels i.e.\n",
        "                   the digit corresponding to the image(s)\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
        "        with pyro.plate(\"data\"):\n",
        "\n",
        "            # if the class label (the digit) is not supervised, sample\n",
        "            # (and score) the digit with the variational distribution\n",
        "            # q(y|x) = categorical(alpha(x))\n",
        "            if ys is None: \n",
        "                alpha = self.encoder_y.forward(xs)\n",
        "                ys = pyro.sample(\"y\", dist.OneHotCategorical(alpha))\n",
        "\n",
        "            # sample (and score) the latent handwriting-style with the variational\n",
        "            # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
        "            loc, scale = self.encoder_z.forward([xs, ys])\n",
        "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
        "\n",
        "    def classifier(self, xs):\n",
        "        \"\"\"\n",
        "        classify an image (or a batch of images)\n",
        "\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :return: a batch of the corresponding class labels (as one-hots)\n",
        "        \"\"\"\n",
        "        # use the trained model q(y|x) = categorical(alpha(x))\n",
        "        # compute all class probabilities for the image(s)\n",
        "        alpha = self.encoder_y.forward(xs)\n",
        "\n",
        "        # get the index (digit) that corresponds to\n",
        "        # the maximum predicted class probability\n",
        "        res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "        # convert the digit(s) to one-hot tensor(s)\n",
        "        ys = torch.zeros_like(alpha).scatter_(1, ind, 1.0)\n",
        "        return ys\n",
        "\n",
        "    def model_classify(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        this model is used to add an auxiliary (supervised) loss as described in the\n",
        "        Kingma et al., \"Semi-Supervised Learning with Deep Generative Models\".  It \n",
        "        probably isn't needed here.\n",
        "        \"\"\"\n",
        "        # register all pytorch (sub)modules with pyro\n",
        "        pyro.module(\"ss_vae\", self)\n",
        "\n",
        "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
        "        with pyro.plate(\"data\"):\n",
        "            # this here is the extra term to yield an auxiliary loss that we do gradient descent on\n",
        "            if ys is not None:\n",
        "                alpha = self.encoder_y.forward(xs)\n",
        "                with pyro.poutine.scale(scale=self.aux_loss_multiplier):\n",
        "                    pyro.sample(\"y_aux\", dist.OneHotCategorical(alpha), obs=ys)\n",
        "\n",
        "    def guide_classify(self, xs, ys=None):\n",
        "        \"\"\"\n",
        "        dummy guide function to accompany model_classify in inference\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPdgbk1kMEjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_data_loaders(train_x, train_y, test_x, test_y, batch_size=128, use_cuda=USE_CUDA):\n",
        "    train_dset = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(train_x.astype(np.float32)).reshape(-1, 4096),\n",
        "        torch.from_numpy(train_y.astype(np.float32))\n",
        "    )\n",
        "    test_dset = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(test_x.astype(np.float32)).reshape(-1, 4096),\n",
        "        torch.from_numpy(test_y.astype(np.float32))\n",
        "    )    \n",
        "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
        "    loader = {}\n",
        "    loader[\"sup\"] = torch.utils.data.DataLoader(\n",
        "        dataset=train_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=test_dset, batch_size=batch_size, shuffle=False, **kwargs\n",
        "    )\n",
        "    loader[\"valid\"] = test_loader\n",
        "    loader[\"test\"] = test_loader\n",
        "    return loader\n",
        "\n",
        "def run_supervized_inference_for_epoch(data_loaders, losses):\n",
        "    \"\"\"\n",
        "    runs the inference algorithm for an epoch\n",
        "    returns the values of all losses separately on supervised and unsupervised parts\n",
        "    \"\"\"\n",
        "    num_losses = len(losses)\n",
        "\n",
        "    # compute number of batches for an epoch\n",
        "    batches_per_epoch = len(data_loaders[\"sup\"])\n",
        "\n",
        "    # initialize variables to store loss values\n",
        "    epoch_losses = [0.] * num_losses\n",
        "\n",
        "    # setup the iterators for training data loaders\n",
        "    sup_iter = iter(data_loaders[\"sup\"])\n",
        "\n",
        "    for i in range(batches_per_epoch):\n",
        "\n",
        "        # extract the corresponding batch\n",
        "        (xs, ys) = next(sup_iter)\n",
        "\n",
        "        # run the inference for each loss with supervised or un-supervised\n",
        "        # data as arguments\n",
        "        for loss_id in range(num_losses):\n",
        "            new_loss = losses[loss_id].step(xs, ys)\n",
        "            epoch_losses[loss_id] += new_loss\n",
        "\n",
        "    # return the values of all losses\n",
        "    return epoch_losses\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad6H4X0HMEjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_zip = np.load(\n",
        "    '/content/gdrive/My Drive/data-science/causal-ml/projects/dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',\n",
        "    encoding = 'bytes',\n",
        "    allow_pickle=True\n",
        ")\n",
        "imgs = dataset_zip['imgs']\n",
        "latents_values = dataset_zip['latents_values']\n",
        "latents_classes = dataset_zip['latents_classes']\n",
        "metadata = dataset_zip['metadata'][()]\n",
        "\n",
        "latents_sizes = metadata[b'latents_sizes']\n",
        "latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:],\n",
        "                                np.array([1,])))\n",
        "\n",
        "def latent_to_index(latents):\n",
        "      return np.dot(latents, latents_bases).astype(int)\n",
        "\n",
        "\n",
        "def sample_latent(size=1):\n",
        "    samples = np.zeros((size, latents_sizes.size))\n",
        "    for lat_i, lat_size in enumerate(latents_sizes):\n",
        "        samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
        "\n",
        "    return samples\n",
        "\n",
        "# Sample latents randomly\n",
        "latents_sampled = sample_latent(size=70000)\n",
        "\n",
        "# Select images\n",
        "indices_sampled = latent_to_index(latents_sampled)\n",
        "imgs_sampled = imgs[indices_sampled]\n",
        "\n",
        "data_loaders = setup_data_loaders(\n",
        "    imgs_sampled[1000:], latents_sampled[1000:],\n",
        "    imgs_sampled[:1000], latents_sampled[:1000],\n",
        "    batch_size=256,\n",
        "    use_cuda=USE_CUDA\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvn38eq0MEjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(data_loader, classifier_fn, batch_size):\n",
        "    \"\"\"\n",
        "    compute the accuracy over the supervised training set or the testing set\n",
        "    \"\"\"\n",
        "    predictions, actuals = [], []\n",
        "\n",
        "    # use the appropriate data loader\n",
        "    for (xs, ys) in data_loader:\n",
        "        # use classification function to compute all predictions for each batch\n",
        "        predictions.append(classifier_fn(xs))\n",
        "        actuals.append(ys)\n",
        "\n",
        "    # compute the number of accurate predictions\n",
        "    accurate_preds = 0\n",
        "    for pred, act in zip(predictions, actuals):\n",
        "        for i in range(pred.size(0)):\n",
        "            v = torch.sum(pred[i] == act[i])\n",
        "            accurate_preds += (v.item() == 10)\n",
        "\n",
        "    # calculate the accuracy between 0 and 1\n",
        "    accuracy = (accurate_preds * 1.0) / (len(predictions) * batch_size)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def visualize(s_vae, viz, test_loader):\n",
        "    if viz:\n",
        "        plot_conditional_samples_ssvae(s_vae, viz)\n",
        "        mnist_test_tsne_ssvae(ssvae=s_vae, test_loader=test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pz3enLBMEjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sup_vae = SVAE(\n",
        "    output_size=6,\n",
        "    input_size=4096,\n",
        "    z_dim=50,\n",
        "    hidden_layers=[500],\n",
        "    use_cuda=USE_CUDA,\n",
        "    config_enum=\"parallel\",\n",
        "    aux_loss_multiplier=46\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4kr9m3UMEja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam_params = {\"lr\": 0.00042, \"betas\": (0.9, 0.999)}\n",
        "optimizer = Adam(adam_params)\n",
        "# set up the loss(es) for inference. wrapping the guide in config_enumerate builds\n",
        "# the loss as a sum\n",
        "# by enumerating each class label for the sampled discrete categorical distribution\n",
        "# in the model\n",
        "guide = config_enumerate(sup_vae.guide, \"parallel\", expand=True)\n",
        "elbo = Trace_ELBO(max_plate_nesting=1)\n",
        "loss_basic = SVI(sup_vae.model, guide, optimizer, loss=elbo)\n",
        "\n",
        "# build a list of all losses considered\n",
        "losses = [loss_basic]\n",
        "loss_aux = SVI(sup_vae.model_classify, sup_vae.guide_classify, optimizer, loss=elbo)\n",
        "losses.append(loss_aux)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0dRPWlWeG64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "30d429c8-59fe-4d0e-b6b9-9bbe34767550"
      },
      "source": [
        "sup_vae"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVAE(\n",
              "  (encoder_y): MLP(\n",
              "    (sequential_mlp): Sequential(\n",
              "      (0): ConcatModule()\n",
              "      (1): DataParallel(\n",
              "        (module): Linear(in_features=4096, out_features=500, bias=True)\n",
              "      )\n",
              "      (2): Softplus(beta=1, threshold=20)\n",
              "      (3): Linear(in_features=500, out_features=6, bias=True)\n",
              "      (4): Softmax()\n",
              "    )\n",
              "  )\n",
              "  (encoder_z): MLP(\n",
              "    (sequential_mlp): Sequential(\n",
              "      (0): ConcatModule()\n",
              "      (1): DataParallel(\n",
              "        (module): Linear(in_features=4102, out_features=500, bias=True)\n",
              "      )\n",
              "      (2): Softplus(beta=1, threshold=20)\n",
              "      (3): ListOutModule(\n",
              "        (0): Sequential(\n",
              "          (0): Linear(in_features=500, out_features=50, bias=True)\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): Linear(in_features=500, out_features=50, bias=True)\n",
              "          (1): Exp()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): MLP(\n",
              "    (sequential_mlp): Sequential(\n",
              "      (0): ConcatModule()\n",
              "      (1): DataParallel(\n",
              "        (module): Linear(in_features=56, out_features=500, bias=True)\n",
              "      )\n",
              "      (2): Softplus(beta=1, threshold=20)\n",
              "      (3): Linear(in_features=500, out_features=4096, bias=True)\n",
              "      (4): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfoFJZPVMEjb",
        "colab_type": "code",
        "outputId": "ae4ce363-8def-43cc-a515-05df5c2ac82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sup_num = 60000\n",
        "batch_size = 256\n",
        "num_epochs = 50\n",
        "\n",
        "logger = open(\"./tmp.log\", \"w\")\n",
        "# Number of supervised number\n",
        "\n",
        "# initializing local variables to maintain the best validation accuracy\n",
        "# seen across epochs over the supervised training set\n",
        "# and the corresponding testing set and the state of the networks\n",
        "best_valid_acc, corresponding_test_acc = 0.0, 0.0\n",
        "\n",
        "# run inference for a certain number of epochs\n",
        "for i in range(0, num_epochs):\n",
        "\n",
        "    # get the losses for an epoch\n",
        "    epoch_losses_sup = run_supervized_inference_for_epoch(\n",
        "        data_loaders,\n",
        "        losses\n",
        "    )\n",
        "\n",
        "    # compute average epoch losses i.e. losses per example\n",
        "    avg_epoch_losses_sup = map(lambda v: v / sup_num, epoch_losses_sup)\n",
        "\n",
        "    # store the loss and validation/testing accuracies in the logfile\n",
        "    str_loss_sup = \" \".join(map(str, avg_epoch_losses_sup))\n",
        "\n",
        "    str_print = \"{} epoch: avg loss {}\".format(i, \"{}\".format(str_loss_sup))\n",
        "\n",
        "    validation_accuracy = get_accuracy(data_loaders[\"valid\"], sup_vae.classifier, batch_size)\n",
        "    str_print += \" validation accuracy {}\".format(validation_accuracy)\n",
        "\n",
        "    # this test accuracy is only for logging, this is not used\n",
        "    # to make any decisions during training\n",
        "    test_accuracy = get_accuracy(data_loaders[\"test\"], sup_vae.classifier, batch_size)\n",
        "    str_print += \" test accuracy {}\".format(test_accuracy)\n",
        "\n",
        "    # update the best validation accuracy and the corresponding\n",
        "    # testing accuracy and the state of the parent module (including the networks)\n",
        "    if best_valid_acc < validation_accuracy:\n",
        "        best_valid_acc = validation_accuracy\n",
        "        corresponding_test_acc = test_accuracy\n",
        "        \n",
        "    visualize(sup_vae, None, data_loaders[\"test\"])\n",
        "\n",
        "    print_and_log(logger, str_print)\n",
        "\n",
        "final_test_accuracy = get_accuracy(data_loaders[\"test\"], sup_vae.classifier, batch_size)\n",
        "print_and_log(logger, \"best validation accuracy {} corresponding testing accuracy {} \"\n",
        "              \"last testing accuracy {}\".format(best_valid_acc, corresponding_test_acc, final_test_accuracy))\n",
        "\n",
        "# close the logger file object if we opened it earlier\n",
        "logger.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0e947718857f>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, xs, ys)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# where `decoder` is a neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/custom_mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/custom_mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0minput_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for sequence element 1 in sequence argument at position #1 'tensors'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5f184cc42a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     epoch_losses_sup = run_supervized_inference_for_epoch(\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-321bd14e9d2e>\u001b[0m in \u001b[0;36mrun_supervized_inference_for_epoch\u001b[0;34m(data_loaders, losses)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# data as arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mloss_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mnew_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mepoch_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 52\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mguide_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m---> 45\u001b[0;31m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcheck_model_guide_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 six.reraise(exc_type,\n\u001b[1;32m    152\u001b[0m                             \u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"{}\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             traceback)\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_RETURN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_RETURN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"return\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0e947718857f>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, xs, ys)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# where `decoder` is a neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# return the loc so we can visualize it later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/custom_mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# pass through our sequential for the output!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/custom_mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input_args)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0minput_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for sequence element 1 in sequence argument at position #1 'tensors'\n                                    Trace Shapes:             \n                                     Param Sites:             \nss_vae$$$encoder_y.sequential_mlp.1.module.weight  500 4096   \n  ss_vae$$$encoder_y.sequential_mlp.1.module.bias       500   \n       ss_vae$$$encoder_y.sequential_mlp.3.weight    6  500   \n         ss_vae$$$encoder_y.sequential_mlp.3.bias         6   \nss_vae$$$encoder_z.sequential_mlp.1.module.weight  500 4102   \n  ss_vae$$$encoder_z.sequential_mlp.1.module.bias       500   \n   ss_vae$$$encoder_z.sequential_mlp.3.0.0.weight   50  500   \n     ss_vae$$$encoder_z.sequential_mlp.3.0.0.bias        50   \n   ss_vae$$$encoder_z.sequential_mlp.3.1.0.weight   50  500   \n     ss_vae$$$encoder_z.sequential_mlp.3.1.0.bias        50   \n  ss_vae$$$decoder.sequential_mlp.1.module.weight  500   56   \n    ss_vae$$$decoder.sequential_mlp.1.module.bias       500   \n         ss_vae$$$decoder.sequential_mlp.3.weight 4096  500   \n           ss_vae$$$decoder.sequential_mlp.3.bias      4096   \n                                    Sample Sites:             \n                                           z dist  256    | 50\n                                            value  256    | 50\n                                           y dist  256    |  6\n                                            value  256    |  6"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQG4d6NgMEjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4334c6da-85f0-4d4e-bb92-4708faf871d7"
      },
      "source": [
        "#torch.save(sup_vae.state_dict(), 'sup_vae')\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0yHxTNMEjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruct_image_w_label(xs, ys, vae):\n",
        "    # backward\n",
        "    sim_z_loc, sim_z_scale = vae.encoder_z([xs, ys])\n",
        "    zs = dist.Normal(sim_z_loc, sim_z_scale).to_event(1).sample()\n",
        "    # forward\n",
        "    loc = vae.decoder([zs, ys])\n",
        "    return dist.Bernoulli(loc).to_event(1).sample()\n",
        "\n",
        "def reconstruct_image(xs, vae):\n",
        "    # backward\n",
        "    sim_ys = vae.encoder_y(xs)\n",
        "    sim_z_loc, sim_z_scale = vae.encoder_z([xs, sim_ys])\n",
        "    zs = dist.Normal(sim_z_loc, sim_z_scale).to_event(1).sample()\n",
        "    # forward\n",
        "    loc = vae.decoder([zs, ys])\n",
        "    return dist.Bernoulli(loc).to_event(1).sample()\n",
        "\n",
        "def convert_back(x):\n",
        "    return x.reshape(-1, 64, 64).numpy().astype(np.uint8)\n",
        "\n",
        "def show_images_grid(imgs_, num_images=25):\n",
        "    ncols = int(np.ceil(num_images**0.5))\n",
        "    nrows = int(np.ceil(num_images / ncols))\n",
        "    _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for ax_i, ax in enumerate(axes):\n",
        "        if ax_i < num_images:\n",
        "          ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
        "          ax.set_xticks([])\n",
        "          ax.set_yticks([])\n",
        "        else:\n",
        "          ax.axis('off')\n",
        "\n",
        "def viz_images(imgs, n):\n",
        "    imgs_ = []\n",
        "    for i, x in enumerate(imgs):\n",
        "        if i > n:\n",
        "            break\n",
        "        imgs_.append(convert_back(x))\n",
        "    show_images_grid(np.array(imgs_), n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm-CLHjBMEjg",
        "colab_type": "text"
      },
      "source": [
        "Four original images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7trYLCqMEjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sup_iter = iter(data_loaders[\"sup\"])\n",
        "xs, ys = next(sup_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVQmHBd_MEji",
        "colab_type": "code",
        "outputId": "27413718-c684-4658-ba77-a9eaa3a209c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "print(\"With y and x:\")\n",
        "xs_sim1 = reconstruct_image_w_label(xs, ys, sup_vae)\n",
        "viz_images(xs_sim1, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With y and x:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f8eb1480df51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"With y and x:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxs_sim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstruct_image_w_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msup_vae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mviz_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_sim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-1283fe49ec4e>\u001b[0m in \u001b[0;36mviz_images\u001b[0;34m(imgs, n)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimgs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mshow_images_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-1283fe49ec4e>\u001b[0m in \u001b[0;36mshow_images_grid\u001b[0;34m(imgs_, num_images)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAF9CAYAAAA5sn5kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEvI9XGTMEjk",
        "colab_type": "code",
        "outputId": "8a3ebd3e-c290-4446-8fee-4219cf91cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "print(\"With just x:\")\n",
        "# backward\n",
        "xs_sim2 = reconstruct_image(xs, sup_vae)\n",
        "viz_images(xs_sim2, 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With just x:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d13c4b71bdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxs_sim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstruct_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msup_vae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mviz_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_sim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-1283fe49ec4e>\u001b[0m in \u001b[0;36mviz_images\u001b[0;34m(imgs, n)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimgs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mshow_images_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-1283fe49ec4e>\u001b[0m in \u001b[0;36mshow_images_grid\u001b[0;34m(imgs_, num_images)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAF9CAYAAAA5sn5kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3W+MXXd95/H3d22PYw/4et08IGmk\nki1jRQJRXCS0RLY7g7CRNyJKURI3CLVJsWqHBFT1QUjVZmNk+oCu2AdA4jjyCifStktaRJrITgkp\nM9jTNEgRxiEuqm2tXW1IK6DBYzJ2PP7z2wfnjLmZuXfmnHvn5ztjv1/S0fE953d+c+4v35vP/XP+\nREoJSZLm2n/q9Q5Ikq5MBowkKQsDRpKUhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWtQIm\nIj4VETsj4qWIOB0RKSK2d/KHI+KOiHgxIt6MiLGI+IeI+EgnfUmdsqalfBbXbP9F4DeAXwCvA7/Z\nyR+NiAeALwE/A75eLt4MvBARd6WUvtFJv1IHrGkpk6hzLbKI+ChwLKV0IiLupnghfSGltL1GH+8B\n/hkYA9aklF4rl98AHKT4VPVfUkpjlXdM6pA1LeVT6yuylNILKaUTXf7Ne4AlwFcnX4hl368BXwNW\nAXd0+TekSqxpKZ9e/Mg/WM6fb7Hu21PaSAvBYDm3pqUmdX+DmQury/nRFusmlw202zgiTs7SfwNI\nwKn6u6arXF85fzAi/rj89wrgYkpppteKNa2FrEqNd6QXAdMo562+j558Aa3s8m9Eo9FozN5M+pWJ\niQnOnDnD0qVLl15zzTVLAcbGxmD2T/rWtBasijXekV4ETFdSSjO+UCPiZKPRaJw8OdubQunt9uzZ\nwz333MODDz7I9u3bAVi5ciVjY2NZPzlY0+qlnDXei99gJt/ltXo3tqKc+0rSQmJNSy30ImCOlPNW\n30lPLmv1XbY0X1nTUgu9CJiRcr6xxbqPTWkjLQQj5dyalppkC5iIaETETRFx3ZRVXwfOAZ8tT0Sb\nbH8DcD/wBvC3ufZL6pQ1LdVT60f+iNgCrC0fvqec3xYR7y7/PZpS2l3++3cpXnhPAHdP9pFSOhYR\nf05xWY0fRMTkJTQ2A78G3JVS8vtqXRa7d+9mdHQUgGPHjgHw9NNPc+LECaA4sqyJNS3VUPcosrXA\nH0xZ9lvlNGk3s0gp/WVEnAD+BPhD4ALwMvDFlNJ3a+6T1LHR0VGeeOKJty07dOgQhw4dAmDJkiWV\n+rGmpelqXYtsIfCQTs2l8hDOsdkOJc7JmlZOOWvc+8FIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNG\nkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIw\nYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQp\nCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBI\nkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYG\njCQpCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsagdMRKyJiGci4o2IOBMRByNia0RExe0H\nIyLNMG2r/zSkzh08eJBbb72VVatWsWzZMtasWcOuXbtIKVXa3pqWWltcp3FErAO+AwTwFPA6cAvw\nGPB+4L4a3X0PGGmx/OU6+yR148CBA2zYsIGUEnfeeSfXX389e/fuZdu2bbzyyit1u7OmpSaVAyYi\nFgP/C1gK/LeU0nPl8oeAF4DPRMT/SSkdqNjlSEppe839lebM+fPn+fSnP83Zs2fZt28fmzZtAmDH\njh189KMf5dFHH6W/v79Ol9a01KTOV2RDwAAwPBkuACmlCeCh8uHWOdw3Kavh4WGOHj3K0NDQpXAB\n6OvrY8eOHQBMTEz0avekBa/OV2SD5fz5FutGgfGmNlUMRMRngXcA/0bx7u9Eje2lroyMjACwcePG\naevWrl1Lf38/p0+frtOlNS01qRMwq8v50akrUkoXIuI48L6IWJ5SqvKq/GQ5TboYEU8C9820fUSc\nnKXfRoW/LXHkyBEABgYGpq1btGgRN954I6+++mqdLq1pqUmdr8gmi3yszfpTU9q18zPg88B7Kd7p\nvQv4BHAMuBt4osY+SR0bGytKudFoXbIrVqyY/OdsR0ha01ILtY4imwsppcPA4aZF48C3IuL7wI+A\n2yNiTUrpYJvtV87Uf/lu0Hd8umysaam1Op9gJj+5tCv0FVPa1ZJSeh3YVz5c20kfUh2Tn1wmP8lM\nderU5Idyqp0QM4U1ratdnYA5Us6nfWEdEYuAG4GfVPz9pZ2fl/Nax4ZKnVi9uvhZ8ejRaT8rcuHC\nBY4fP07F84dnYk3rqlUnYEbK+fRDbop3Z/20Psmsjg+V8+Nd9iPNanBwEIDnn59+YOTo6Cjj4+Ms\nXtz1t8jWtK5adQJmmOIIsqGIuHTSQET0ATvKh483Lb82Im6KiGubO4mID07tOAoPADcDbwB/X2O/\npI4MDQ0xMDDA8PAwzz136dQuJiYmeOih4tSuvr6+S8utaameym/PUkrnI2ILxXkwT0fENyiO9b+F\n4uiZnSml/U2b3A88DHwB2N60/JsRcY7i8hmvURx1czPFpWbeAn4/pdTR7zhSHYsXL2b37t1s3LiR\n2267jc2bN3Pdddexd+9eDh8+zL333stf/dVfNW9iTUs11LrYZRkgN1OEzMeBzwEXgHupfh2yncC/\nAusoXrB3A8uAXcBvpZT21tknqRvr16/nxRdfZOPGjTz77LN85StfYdGiRezcuZNHHnmkajfWtNRC\nVL1i7EIREScbjUbj5MnZzl2TZrdy5UrGxsbGZjuUOCdrWjnlrHHvByNJysKAkSRlYcBIkrIwYCRJ\nWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNG\nkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIw\nYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQp\nCwNGkpSFASNJysKAkSRlYcBIkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBI\nkrIwYCRJWRgwkqQsDBhJUhYGjCQpCwNGkpSFASNJysKAkSRlYcBIkrLoKGAiYk1EPBMRb0TEmYg4\nGBFbIyJq9BERsa3c9kzZ199FxAc62SepUwcPHuTWW29l1apVLFu2jDVr1rBr1y5SSpX7sJ6l6RbX\n3SAi1gHfAQJ4CngduAV4DHg/cF/Frh4B7gX+FXgUeCfwe8DHImJDSulA3X2T6jpw4AAbNmwgpcSd\nd97J9ddfz969e9m2bRuvvPJKna6sZ2mqlFLliSKQjgAJ2NS0vA/YXy5fV6Gf9WXbfwEaTcs/ALxV\nLl9UZ9+a+jjZaDSSNJtz586lgYGBBKR9+/ZdWn727Nm0bt26BKT+/v4EnEw9qudkTSuzRqMxa413\nOtX9imwIGACGU0rPNYXUBPBQ+XBrhX4m2/xFSmmsqZ8fAn8NrC7/lpTN8PAwR48eZWhoiE2bNl1a\n3tfXx44dOwCYmJio0pX1LLVQN2AGy/nzLdaNAuNNbTrt59tT2khZjIyMALBx48Zp69auXUt/fz/n\nz5+v0tVgObeepSaR6v2Q+TfA7cDtKaVvtlj/I+B9QH9K6XSbPvqBN4E3U0rvbLH+g8DLwFMppc0t\n1p+cZTcbAI1GY5ZmutqNj49z/vx5li9fzpIlS6at/+Uvf8nFixcBUkqp5Zuxbuu5bGNNq2fGxsZg\nhhrvRt0f+ScrfKzN+lNN7VoGTI0+VtbbtbcbK0dNbc323+Fq0A8sPn369DjQ6qPKO4BFFAe0tHNZ\n6hms6Rqs7XoazFzjHat9FFmvpZRmfKFOvhucrd3VznGCiHge2ADcllJ6ocX6fwRu5lchkYU1Pbcc\nr3oqfILuWN2PRJPvCNp9Vl8xpV03fWR70lKpai3O9D2y9Sy1UTdgjpTzgakrImIRcCPwk3a/vwCk\nlMYpzp15R0S8q0WTyb6P1tw3qa4q9Tzjj5TWs9Re3YAZKefTD7uBtRTfaY+0WFenn49NaSPlMlLO\nZ6rnKoeRzdSP9ayrVt2AGaZ4JzYUEZdOHIiIPmBH+fDxpuXXRsRNEXHtlH4m2/xZRDSa2n8AuKv8\nG8M1902qq0o9n21abj1LNdQKmJTSeWALxYvu6Yh4MiK+BPwAWAfsTCntb9rkfuDH5by5n+8BOylO\nQDsUEV+OiMcprgYA8OmU0oVOnpBUVZV6Bprr0HqWaqh93HMZIDdTnFT2ceBzFC/Ce6l+HTLKtp+h\n+JH0M8AdFF8jfDh53SZdJtazlE+tEy0XAg9RrMZxqmY+jNN82IeFxPGqJ+d4XXEBI0maH7zhmCQp\nCwNGkpSFASNJysKAkSRlsSACJiLWRMQz5X3Oz5T3Pd8aEZWvAHo13DO923GKiMGISDNM23I/h9wi\n4lMRsTMiXoqI0+Xz2t5hX3dExIsR8WZEjEXEP0TERypsZz3XYF1XNx/qu9m8v5pyRKwDvkNxOemn\nKK77dAvwGPB+qp+rcEXfM30Oxwnge7S+tMnL3e3lvPBF4DeAX1CM0W920klEPAB8CfgZ8PVy8Wbg\nhYi4K6X0jTbbWc81WNe19bS+p8lxH+a5migC8AjFBQc3NS3vozhLOgHrKvST9Z7pvZ7mcJwGy7bb\ne/2cMo7VR4F3l/++u5PnC7wHmChffDc0Lb+hXPYfzXWW4b/TFV3PGcbriq/rpufas/puNc33r8iG\nKK5GO5xSem5yYUppAniofLi11YZTXOn3TJ+rcbripZReSCmd6LKbe4AlwFdTSq819f0a8DVgFcWZ\n/FNZz/VY1zX1uL6nme8BM1jOW93rfBQYp9q9zmfq50q4Z/pgOe92nCYNRMRnI+JPI+LuiHh3V3t3\n5Rks53XraabtrOfpBsu5dX15DZbzrutrvv8Gs7qcT7uXRkrpQkQcB94XEctTm3vQRHHP9Osp7pn+\n7y2aTPY97Z4gC0jX4zTFJ8tp0sWIeBK4r+L2V7q2483M9WQ912Nd90an9T3NfP8EU/V+5+3uJlin\nj4V83aK5GCcovl/9PPBeivvRvwv4BHCM4vvcJ7rayyvHTOM9Uz1Zz/VY173RaX1PM98/wegySikd\nBg43LRoHvhUR3wd+BNweEWtSSgd7soNSB6zr3pnvn2Cq3u+83TucOn0s5Humz8U4tZVSeh3YVz5c\n20kfV5iZxnumerKe67Gue6PT+p5mvgdMlXum/2Sm70/T1XHP9K7HqYKfl/P+Lvq4UrQdb2auJ+u5\nHuu6Nzqt72kqBUwPzw4dKecz3TN9pMW6Ov1cCfdMHynn3Y7TTD5Uzo932c98dEvN2h4p528b74i4\ng+JkQIBPtKjtltuVrOfpRsq5dX15jZTz7uur4ok3JyhO2HmD4oexjk5aAh4ot/0p8NVy+ilwEdjc\non2VE63WNy2/FrgJuHZKP7/DzCemHWEBn5g2h+P0wRZ9R9N/t8onWC2EiV+diNaytim+IrgJuG7K\ndtNORGsao4vAGWDX1Nq2nq3rHtX39jbrK9d3ubz5RMuVlfah4o728uzn9eWL5izwJMXlC14t9+HR\nKW23t9s3istpJIqw/DLwOMUREW9R4Wzg+T7NxTiVY3OU4mS9/0Fxn/lDZdszwC29fp5zME5bgD3l\nNFo+t3+e8nj7lFrf06Kf5jdLT1LcZvkibw+UabVtPVvXPajvHzYt29LUtmp9z/phoO3+dPAEJndq\ne83t/qLc7r+3WPdwuW5Lm21/G3iW4vo6Z8ri2EZ5R87ZCqxcFxTXbjpU9vEL4BlgTa+LYg6Lq6tx\nojiU8wXgtXL7MxTvIB8DVvf6+c3RGO3hV59a2k3by7ZtX4Dl+juBlyjeOCXg/wIfma22rWfruof1\nvaepbdX6Hqd48/LdqfU921T7lskRcTfFxc++kFLaXmO7fwRuBj6cUnppyrr/CvwT8L9TSp+qtUPS\nHLG2pbl1Oc+D6ers0IiY7bC4BkUan5qlndROXzl/MCL+eMq6FcDFlFKr14y1rYVsptruyuUMmDk7\nO3QG0Wg0ZjurV2ppYmKCM2fOsHTp0qXXXHPN0uZ1Y2Nj0P6oS2tbC9Ystd2VBXMmf0ppxhdoRJxs\nNBqNkyevhPPL1At79uzhnnvu4cEHH2T79u1vW7dy5UrGxsayfIKwttVLOWv7cp5oOWdnh0rzjLUt\ntXA5A2bOzg6V5hlrW2rhcgbMSDm/0s8+1tVnpJxb21KTOQ+YiGhExE0Rcd2UVV8HzgGfjYgbmtrf\nANxPcSb13871/khzydqWqqv0I39EbOFXVxt9Tzm/remOcKMppd3lv3+X4gX3BMWJPACklI5FxJ9T\nnIn7g4j4RrlqM/BrwF0pJb+n1mW1e/duRkdHATh27BgATz/9NCdOnABg7dq1bNmyZbJ5H/BjrG2p\nkqpHka0F/mDKst8qp0m7mUVK6S8j4gTwJ8AfUlxe42Xgiyml71bcF2nOjI6O8sQTb7/f1KFDhzh0\n6NClx00B05a1LU1X+0z++cpDOZVTeSjn2GyHFOdgbSunnLU93+8HI0laoAwYSVIWBowkKQsDRpKU\nhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWBowkKQsDRpKUhQEjScrCgJEkZWHASJKyMGAk\nSVkYMJKkLAwYSVIWBowkKQsDRpKUhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWBowkKQsD\nRpKUhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWBowkKQsDRpKUhQEjScrCgJEkZWHASJKy\nMGAkSVkYMJKkLAwYSVIWBowkKQsDRpKUhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWBowk\nKQsDRpKUhQEjScrCgJEkZWHASJKyMGAkSVkYMJKkLAwYSVIWBowkKYvKARMRayLimYh4IyLORMTB\niNgaEVFx+8GISDNM2zp/GlLnDh48yK233sqqVatYtmwZa9asYdeuXaSUKm1vbUutLa7SKCLWAd8B\nAngKeB24BXgMeD9wX42/+T1gpMXyl2v0Ic2JAwcOsGHDBlJK3HnnnVx//fXs3buXbdu28corr/DI\nI4/U6c7alpqllGacKELoCJCATU3L+4D95fJ1FfoZLNtun61tJxNwstFoJKmqc+fOpYGBgQSkffv2\nXVp+9uzZtG7dugSk/fv3p5RSajQaCTiZrG1dYWaq7W6nKl+RDQEDwHBK6bmmYJoAHiofbu0w36Se\nGR4e5ujRowwNDbFp06ZLy/v6+tixYwcAu3bt6tXuSQtela/IBsv58y3WjQLjTW2qGIiIzwLvAP4N\nGEkpnaixvTQnRkZGANi4ceO0dWvXrqW/v/9Sm4qsbalJlYBZXc6PTl2RUroQEceB90XE8pTS6Qr9\nfbKcJl2MiCeB+2baPiJOztJvo8Lfli45cuQIAAMDA9PWLVq0iBtvvJFXX32V06erlDVgbUtvU+Ur\nssniHmuz/tSUdu38DPg88F6Kd3jvAj4BHAPuBp6osC/SnBkbK0q60WhduitWrHhbuxlY21ILlY4i\nmwsppcPA4aZF48C3IuL7wI+A2yNiTUrpYJvtV87Uf/ku0Hd6uuysbam1Kp9gJt++tSvwFVPa1ZJS\neh3YVz5c20kfUicmP7m0+4Ry6tSpt7Wry9rW1a5KwBwp59O+qI6IRcCNwE8q/v7Szs/LeX8XfUi1\nrF5d/Lx49Oi0nxe5cOECx48f59d//ddZvnx5N3/G2tZVq0rAjJTz6YfaFO/K+ml9clkdHyrnx7vs\nR6pscHAQgOefn36A5OjoKOPj45fadMHa1lWrSsAMUxxBNhQRl04WiIg+YEf58PGm5ddGxE0RcW1z\nJxHxwakdR+EB4GbgDeDv6z8FqTNDQ0MMDAwwPDzMc89dOsWLiYkJHnqoOMXrj/7oj5o3CWtbqm7W\nH/lTSucjYgvFeTBPR8Q3KI7xv4XiqJmdKaX9TZvcDzwMfAHY3rT8mxFxjuKyGa9RHG1zM8WlZt4C\nfj+l1NHvOFInFi9ezO7du9m4cSO33XYbmzdv5rrrrmPv3r0cPnyYe++9l/Xr1zdvshT4Mda2VEml\no8hSSvsj4maKF9bHgWsofpu5F6h6qvNOYAOwDvi1ctn/K7f/nymlI+02lHJZv349L774Ig8//DDP\nPvssb731FqtXr2bnzp1s3Vr5AhXWttRCpIpXjJ3vIuJko9FonDw52zlrUn0rV65kbGxsbLZDinOw\ntpVTztr2fjCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCRJGVhwEiSsjBgJElZGDCSpCwMGElSFgaM\nJCkLA0aSlIUBI0nKwoCRJGVhwEiSsjBgJElZGDCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCRJGVh\nwEiSsjBgJElZGDCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCRJGVhwEiSsjBgJElZGDCSpCwMGElS\nFgaMJCkLA0aSlIUBI0nKwoCRJGVhwEiSsjBgJElZGDCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCR\nJGVhwEiSsjBgJElZGDCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCRJGVhwEiSsjBgJElZGDCSpCwM\nGElSFgaMJCmLWgETEWsi4pmIeCMizkTEwYjYGhFRo4+IiG3ltmfKvv4uIj5Qf/el7h08eJBbb72V\nVatWsWzZMtasWcOuXbtIKVXuw7qWpqscMBGxDvgn4GPAXuArwBLgMeBrNf7mI8BO4D8DjwJ/CwwB\nL5V/Q7psDhw4wIc//GG+/e1vc8stt/C5z32Oc+fOsW3bNu6///46XVnX0lQppVknYDFwBEjApqbl\nfcD+cvm6Cv2sL9v+C9BoWv4B4K1y+aIq+9Si75ONRiNJVZ07dy4NDAwkIO3bt+/S8rNnz6Z169Yl\nIO3fvz+llFKj0UjAyXSZ6zpZ28psptrudqr6CWYIGACGU0rPNYXTBPBQ+XBrhX4m2/xFSmmsqZ8f\nAn8NrC7/lpTd8PAwR48eZWhoiE2bNl1a3tfXx44dOwDYtWtXla6sa6mFqgEzWM6fb7FuFBhvatNp\nP9+e0kbKamRkBICNGzdOW7d27Vr6+/svtZnFYDm3rqUmkSr8kBkRfwPcDtyeUvpmi/U/At4H9KeU\nTrfpox94E3gzpfTOFus/CLwMPJVS2txi/clZdrMB0Gg0ZmkmFcbHxzl//jzLly9nyZIl09b/8pe/\n5OLFi6xYsYJTp04BpJTS296UdVvXZRtrWz0zNjYGLWp7Liyu2G6yssfarD/V1K5lwNToY2XFfWpp\nrBwtzWq2/x5Xg35g8enTp8eB8y3WvwNYdKpIlxVAq6MlL0tdg7Vdg7VdT4PWtd21qgHTcymlGV+g\nk+8CZ2unguMFEfE8sAG4LaX0Qov1/wjcDNwE/DjXfljbc8vxqqfCJ+iOVf1INPlOoN1n9BVT2nXT\nR7YnK01hXUsZVQ2YI+V8YOqKiFgE3Aj8pN3vLwAppXHgdeAdEfGuFk0m+z5acZ+kblnXUkZVA2ak\nnE8/3AbWUnyXPdJiXZ1+PjaljZTbSDm3rqUMqgbMMMU7sKGIuHTCQET0ATvKh483Lb82Im6KiGun\n9DPZ5s8iotHU/gPAXeXfGK73FKSO1arrYpV1LVVVKWBSSueBLcBZ4OmIeDIivgT8AFgH7Ewp7W/a\n5H6KH0Xvn9LP9ygup7EaOBQRX46IxymuBgDw6ZTShW6ekFRVB3W9FOtaqqzyUWQppf0RcTPwBeDj\nwDUU32HfC1Q63bl0H/AjYBvwGYpLaYwAD6eUDtboR+qadS3lU+lEy4XAQxPrcbzq6eV4+d+qHser\nnpzjdcUEjCRpfvGGY5KkLAwYSVIWBowkKQsDRpKUxbwOmIhYExHPlPc3P1Pe73xrRFS+8ufVdK/0\nbscrIgYjIs0wbcv9HC6XiPhUROyMiJci4nT5/LZ32NcdEfFiRLwZEWMR8Q8R8ZEZ2lvXNVjX1fWy\nrluZt1dTjuI+5t+huIz0UxTXe7oFeAx4P8V5B1U8QnFOw79S3Cv9ncDvAR+LiA0ppQNzvOs9MYfj\nBfA9Wl/a5OXu9nJe+SLwG8AvKMbqNzvpJCIeAL4E/Az4erl4M/BCRNyVUvrGlPbWdQ3WdW09qeu2\nctyHuduJIviOUNznfFPT8j6Ks6MTsK5CP1nvlT5fpjkcr8Gy7fZeP6fLMGYfBd5d/vvuTp438B5g\nonwR3tC0/IZy2X9MqTvrut74Wtf1x+yy1/VM03z9imyI4iq0wyml5yYXppQmgIfKh1tbbTjF1XKv\n9Lkar6tGSumFlNKJLru5B1gCfDWl9FpT368BXwNWAXc0tbeu67Gua+pRXbc1XwNmsJy3usf5KDBO\ntXucz9TPlXSv9MFy3u14TRqIiM9GxJ9GxN0R8e6u9u7KNVjOq9bXTO2t6+kGy7l1fXkNlvOu62u+\n/gazupxPu4dGSulCRBwH3hcRy1Obe3VEca/06ynulf7vLZpM9j3tXiALUNfjNcUny2nSxYh4Eriv\n4vZXi7bjTuv6sq7rsa57o25dtzVfP8FUvc95u7sI1unjSrhe0VyMFxTfr34eeC/F/ejfBXwCOEbx\nfe4TXe3llWemcW9VX9Z1PdZ1b9St67bm6ycY9UBK6TBwuGnROPCtiPg+xZWCb4+INcmrA2sBsa57\nZ75+gvFe6fXMxXi1lVJ6HdhXPlzbSR9XqJnGvVV9Wdf1WNe9Ubeu25qvAeO90uvperwq+Hk57++i\njytN23GndX1Z1/VY171Rt67bmq8BM1LOvVd6NSPlvNvxmsmHyvnxLvu5koyU86r1NVN763q6kXJu\nXV9eI+W8+/rq9YlBbU70qXIYEB2gAAABY0lEQVSC1fqm5dcCNwHXTunnd5j5hLQjXD0npFUZrw+2\n6DuAB8o+Kp9gtZAmZjkhjeKrgpuA66Ysr3JC2soM/52sa+t63tT1jPvQ60GYYXDWly+Ws8CTFJct\neLUcsEentN3ebiApLqORgBPAl4HHKY6EeIsKZwEvlGkuxqsco6MUJ+v9D4r7zB8q254Bbun185zD\n8doC7Cmn0fI5/rBp2ZamtpMv1D0t+pn8n9RPga+W00+Bi8Bm69q6vhrquu3+9HpAZhms3waepbiu\nzpmyKLZR3olztsIq1wXFNZsOlX38AngGWNPr5zffxoviUM4XgNfK7c9QvIN8DFjd6+c3x2O1pxyD\ndtOeprZtX4jl+juBlyiOTjoFfBf4SK7/TuU669q6nld13WrylsmSpCzm64/8kqQFzoCRJGVhwEiS\nsjBgJElZGDCSpCwMGElSFgaMJCkLA0aSlIUBI0nKwoCRJGXx/wEAiDzZF7qlhQAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x432 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_OtIYKxdNp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}